# Example values for ai-virtual-agent with vision model configuration.
# Copy this file to values.yaml and customize for your deployment.
#
# VISION MODEL CONFIGURATION:
# This example includes the Qwen 2.5 VL 3B vision model configuration
# that enables image interpretation capabilities in the cluster.
#
# Key vision model settings:
# - max-model-len: 20480 (supports ~16K image tokens)
# - gpu-memory-utilization: 0.80 (optimized for memory)
# - max-num-seqs: 4 (balanced concurrency)
#
# TROUBLESHOOTING:
# - Image processing error 500: Usually caused by insufficient max-model-len
# - OOM errors: Reduce max-num-seqs or gpu-memory-utilization
# - Pod scheduling issues: Check GPU node tolerations

# This will set the replicaset count
replicaCount: 1

# Container image configuration
image:
  repository: quay.io/ecosystem-appeng/ai-virtual-agent
  pullPolicy: Always
  # Overrides the image tag whose default is the chart appVersion.
  #tag: "1.1.0"

imagePullSecrets: []
nameOverride: ""
fullnameOverride: ""

# Service account configuration
serviceAccount:
  create: true
  automount: true
  annotations:
    serviceaccounts.openshift.io/oauth-redirectreference.ai-virtual-agent: '{"kind":"OAuthRedirectReference","apiVersion":"v1","reference":{"kind":"Route","name":"ai-virtual-agent-authenticated"}}'
  name: "ai-virtual-agent-proxy-sa"

podAnnotations: {}
podLabels: {}
podSecurityContext: {}
securityContext: {}

# Service configuration
service:
  type: ClusterIP
  port: 8000

# Resource configuration (customize as needed)
resources: {}
  # limits:
  #   cpu: 100m
  #   memory: 128Mi
  # requests:
  #   cpu: 100m
  #   memory: 128Mi

# Health check configuration
livenessProbe:
  httpGet:
    path: /
    port: http
readinessProbe: {}

# Autoscaling configuration
autoscaling:
  enabled: false
  minReplicas: 1
  maxReplicas: 100
  targetCPUUtilizationPercentage: 80

# Volume configuration for TLS and proxy secrets
volumes:
  - name: secret-ai-virtual-agent-tls
    secret:
      defaultMode: 420
      secretName: ai-virtual-agent-tls
  - name: secret-ai-virtual-agent-proxy
    secret:
      defaultMode: 420
      secretName: ai-virtual-agent-proxy

volumeMounts: []
nodeSelector: {}
tolerations: []
affinity: {}

# Database configuration
pgSecret: pgvector

# LlamaStack URL configuration
llama_stack_url: http://llamastack:8321

# Session secret configuration
sessionSecret: {}
 # value: "your-session-secret-here"

# Admin user seed configuration
seed:
  admin_user:
    username: "your-admin@your-domain.com"  # Change this
    email: "your-admin@your-domain.com"     # Change this

# PostgreSQL configuration
pgvector:
  extraDatabases:
  - name: ai_virtual_agent
    vectordb: false

# MinIO configuration
minio:
  secret:
    user: your_minio_user           # Change this
    password: your_minio_password   # Change this
    host: minio
    port: "9000"

  # Upload sample files to the minio bucket
  sampleFileUpload:
    enabled: true
    bucket: documents
    urls:
    - https://raw.githubusercontent.com/burrsutter/sample-pdfs/main/FantaCo/HR/FantaCo-Fabulous-HR-Benefits.pdf

# LlamaStack configuration
llama-stack:
  enabled: true
  auth:
    provider_config:
      type: "custom"
      endpoint: http://ai-virtual-agent:8887/validate
    access_policy:
    - permit:
        actions: [create]
        resource: session::*
      description: all users have create access to sessions
    - permit:
        actions: [read]
        resource: agent::*
      description: all users have read access to agents
    - permit:
        actions: [read]
        resource: tool_group::*
      description: all users have read access to tool_groups
    - permit:
        actions: [read]
        resource: model::*
      description: all users have read access to models
    - permit:
        actions: [read]
        resource: vector_db::*
      description: all users have read access to vector_dbs
    - permit:
        actions: [create, update, delete]
        resource: vector_db::*
      when: user with admin in roles
      description: users with the admin role can create, update or delete vector_dbs
    - permit:
        actions: [create, update, delete]
        resource: tool_group::*
      when: user with admin in roles
      description: users with the admin role can create, update or delete tool_groups
    - forbid:
        actions: [create, update, delete]
      unless: user with admin in roles
      description: only users with the admin role can create, update or delete resources
    - permit:
        actions: [read, update, delete]
      when: user is owner
      description: users can read, update and delete resources they own
  secrets:
    TAVILY_SEARCH_API_KEY: ""  # Add your Tavily API key here

# Global model configuration - VISION MODELS CONFIGURATION
global:
  models:
    # Text model - matches local llama3.2:1b-instruct-fp16 (DISABLED to save resources)
    llama-3-2-1b-instruct:
      id: meta-llama/Llama-3.2-1B-Instruct
      enabled: false

    # Vision model - Qwen 2.5 VL 3B (RECOMMENDED FOR PRODUCTION)
    # This model provides image interpretation capabilities
    qwen-2-5-vl-3b-instruct:
      id: Qwen/Qwen2.5-VL-3B-Instruct
      enabled: true
      # GPU node scheduling
      tolerations:
        - key: g5-gpu
          effect: NoSchedule
          operator: Exists
      # Resource requirements for vision model
      resources:
        limits:
          cpu: "2"
          memory: 16Gi
          nvidia.com/gpu: 1
        requests:
          cpu: "1"
          memory: 8Gi
          nvidia.com/gpu: 1
      # vLLM configuration optimized for image processing
      args:
        - --max-model-len
        - "20480"  # Increased context length for image processing (supports ~16K image tokens)
        - --gpu-memory-utilization
        - "0.80"   # Optimized memory usage
        - --max-num-seqs
        - "4"      # Balanced concurrency for memory efficiency

  # MCP servers configuration
  mcp-servers:
    mcp-weather:
      uri: http://mcp-weather:8000/sse
